{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIBERO Policy Evaluation\n",
    "\n",
    "This notebook evaluates a policy on LIBERO benchmark tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import dataclasses\n",
    "import logging\n",
    "import math, sys, os\n",
    "import pathlib\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "\n",
    "sys.path.append(\"/hdd/zijianwang/openpi/third_party/LIBERO-PRO\")\n",
    "\n",
    "import imageio\n",
    "from libero.libero import benchmark\n",
    "from libero.libero import get_libero_path\n",
    "from libero.libero.envs import OffScreenRenderEnv\n",
    "import numpy as np\n",
    "from openpi_client import image_tools\n",
    "from openpi_client import websocket_client_policy as _websocket_client_policy\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, Any\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Constants and Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIBERO_DUMMY_ACTION = [0.0] * 6 + [-1.0]\n",
    "LIBERO_ENV_RESOLUTION = 256  # resolution used to render training data\n",
    "\n",
    "\n",
    "def _get_libero_env(task, resolution, seed):\n",
    "    \"\"\"Initializes and returns the LIBERO environment, along with the task description.\"\"\"\n",
    "    task_description = task.language\n",
    "    task_bddl_file = pathlib.Path(get_libero_path(\"bddl_files\")) / task.problem_folder / task.bddl_file\n",
    "    env_args = {\"bddl_file_name\": task_bddl_file, \"camera_heights\": resolution, \"camera_widths\": resolution}\n",
    "    print(env_args)\n",
    "    env = OffScreenRenderEnv(**env_args)\n",
    "    env.seed(seed)  # IMPORTANT: seed seems to affect object positions even when using fixed initial state\n",
    "    return env, task_description\n",
    "\n",
    "\n",
    "def _quat2axisangle(quat):\n",
    "    \"\"\"\n",
    "    Copied from robosuite: https://github.com/ARISE-Initiative/robosuite/blob/eafb81f54ffc104f905ee48a16bb15f059176ad3/robosuite/utils/transform_utils.py#L490C1-L512C55\n",
    "    \"\"\"\n",
    "    # clip quaternion\n",
    "    if quat[3] > 1.0:\n",
    "        quat[3] = 1.0\n",
    "    elif quat[3] < -1.0:\n",
    "        quat[3] = -1.0\n",
    "\n",
    "    den = np.sqrt(1.0 - quat[3] * quat[3])\n",
    "    if math.isclose(den, 0.0):\n",
    "        # This is (close to) a zero degree rotation, immediately return\n",
    "        return np.zeros(3)\n",
    "\n",
    "    return (quat[:3] * 2.0 * math.acos(quat[3])) / den\n",
    "def _plot_velocity_trajectory(velocity_trajectory, output_path):\n",
    "    \"\"\"\n",
    "    Plot velocity trajectory with N dimensions as different colored lines.\n",
    "    \n",
    "    Args:\n",
    "        velocity_trajectory: List of N-dimensional velocity vectors or 1D array\n",
    "        output_path: Path to save the plot\n",
    "    \"\"\"\n",
    "    if len(velocity_trajectory) == 0:\n",
    "        logging.warning(\"No velocity data to plot\")\n",
    "        return\n",
    "    \n",
    "    velocity_array = np.array(velocity_trajectory)  # Shape: (T, N) or (T,)\n",
    "    time_steps = np.arange(len(velocity_trajectory))\n",
    "    \n",
    "    # Handle 1D case (T,) by reshaping to (T, 1)\n",
    "    if velocity_array.ndim == 1:\n",
    "        velocity_array = velocity_array.reshape(-1, 1)\n",
    "    \n",
    "    # Get number of dimensions\n",
    "    num_dims = velocity_array.shape[1]\n",
    "    \n",
    "    # Create figure with good size\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Define colors - use a colormap for arbitrary number of dimensions\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, max(num_dims, 1)))\n",
    "    dimension_labels = [f'Joint {i+1}' for i in range(num_dims)]\n",
    "    \n",
    "    # Plot each dimension with different color\n",
    "    for dim in range(num_dims):\n",
    "        plt.plot(time_steps, velocity_array[:, dim], \n",
    "                color=colors[dim], label=dimension_labels[dim], linewidth=1.5, alpha=0.8)\n",
    "    \n",
    "    plt.xlabel('Time Step', fontsize=12)\n",
    "    plt.ylabel('Velocity (rad/s)', fontsize=12)\n",
    "    plt.title('Joint Velocity Trajectory', fontsize=14, fontweight='bold')\n",
    "    plt.legend(loc='best', fontsize=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    plt.savefig(output_path, dpi=100)\n",
    "    plt.close()\n",
    "    \n",
    "    logging.info(f\"Velocity plot saved to: {output_path}\")\n",
    "\n",
    "\n",
    "def add_text_to_image(temp_img, CoA_step):\n",
    "    \"\"\"Add text overlay to image showing length and step number.\n",
    "    \n",
    "    Args:\n",
    "        temp_img (np.ndarray): Input image of shape (224, 224, 3)\n",
    "        num_act_units (int): Number of action units\n",
    "        CoA_step (int): Current step number\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Image with text overlay\n",
    "    \"\"\"\n",
    "    img = temp_img.copy()\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    text = f\"step: {CoA_step}\"\n",
    "    \n",
    "    # Get text size to position it in upper right\n",
    "    (text_width, text_height), _ = cv2.getTextSize(text, font, 0.5, 1)\n",
    "    \n",
    "    # Position text 10 pixels from right and top edges\n",
    "    text_x = img.shape[1] - text_width - 10\n",
    "    text_y = text_height + 10\n",
    "    \n",
    "    # Add white text with black outline for visibility\n",
    "    cv2.putText(img, text, (text_x, text_y), font, 0.5, (0,0,0), 2)\n",
    "    cv2.putText(img, text, (text_x, text_y), font, 0.5, (255,255,255), 1)\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def is_gripper_closed(obs: Dict[str, Any], tolerance: float = 0.005) -> bool:\n",
    "    \"\"\"\n",
    "    根据 robosuite 的 observation 中 'robot0_gripper_qpos' 的值判断夹爪是否闭合。\n",
    "\n",
    "    Args:\n",
    "        obs (Dict[str, Any]): 来自 env.step() 的观察结果字典。\n",
    "        tolerance (float): 判断夹爪是否闭合时的容差阈值。\n",
    "\n",
    "    Returns:\n",
    "        bool: 如果夹爪被认为是闭合的，则返回 True，否则返回 False。\n",
    "    \"\"\"\n",
    "    if 'robot0_gripper_qpos' not in obs:\n",
    "        raise KeyError(\"Observation dictionary does not contain 'robot0_gripper_qpos'.\")\n",
    "\n",
    "    gripper_qpos = obs['robot0_gripper_qpos']\n",
    "    \n",
    "    # 假设夹爪是双指且左右关节位置大小相等、符号相反。\n",
    "    # 我们可以计算两个关节位置的绝对值之和，或计算它们之间的距离。\n",
    "    # 当夹爪闭合时，关节位置接近于0。\n",
    "    # 这里的 total_closure 是一个简化的度量，表示夹爪的闭合程度。\n",
    "    total_closure = np.sum(np.abs(gripper_qpos))\n",
    "    \n",
    "    # 如果总闭合度小于容差，则认为夹爪已闭合。\n",
    "    return total_closure < tolerance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Set Hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters:\n",
      "  Host: 0.0.0.0\n",
      "  Port: 8001\n",
      "  Resize size: 224\n",
      "  Replan steps: 5\n",
      "  Task suite: libero_spatial\n",
      "  Num steps wait: 10\n",
      "  Num trials per task: 1\n",
      "  Video output path: data/libero/videos\n",
      "  Seed: 7\n"
     ]
    }
   ],
   "source": [
    "@dataclasses.dataclass\n",
    "class Args:\n",
    "    #################################################################################################################\n",
    "    # Model server parameters\n",
    "    #################################################################################################################\n",
    "    host: str = \"0.0.0.0\"\n",
    "    port: int = 8001\n",
    "    resize_size: int = 224\n",
    "    replan_steps: int = 5\n",
    "\n",
    "    #################################################################################################################\n",
    "    # LIBERO environment-specific parameters\n",
    "    #################################################################################################################\n",
    "    task_suite_name: str = (\n",
    "        \"libero_10\"  # Task suite. Options: libero_spatial, libero_object, libero_goal, libero_10, libero_90\n",
    "    )\n",
    "    num_steps_wait: int = 10  # Number of steps to wait for objects to stabilize in sim\n",
    "    num_trials_per_task: int = 50  # Number of rollouts per task\n",
    "\n",
    "    #################################################################################################################\n",
    "    # Utils\n",
    "    #################################################################################################################\n",
    "    video_out_path: str = \"data/libero/videos\"  # Path to save videos\n",
    "\n",
    "    seed: int = 7  # Random Seed (for reproducibility)\n",
    "\n",
    "\n",
    "# Create args instance - you can modify these values as needed\n",
    "args = Args(\n",
    "    host=\"0.0.0.0\",\n",
    "    port=8001,\n",
    "    resize_size=224,\n",
    "    replan_steps=5,\n",
    "    task_suite_name=\"libero_spatial\",\n",
    "    num_steps_wait=10,\n",
    "    num_trials_per_task=1,\n",
    "    video_out_path=\"data/libero/videos\",\n",
    "    seed=7\n",
    ")\n",
    "\n",
    "print(\"Hyperparameters:\")\n",
    "print(f\"  Host: {args.host}\")\n",
    "print(f\"  Port: {args.port}\")\n",
    "print(f\"  Resize size: {args.resize_size}\")\n",
    "print(f\"  Replan steps: {args.replan_steps}\")\n",
    "print(f\"  Task suite: {args.task_suite_name}\")\n",
    "print(f\"  Num steps wait: {args.num_steps_wait}\")\n",
    "print(f\"  Num trials per task: {args.num_trials_per_task}\")\n",
    "print(f\"  Video output path: {args.video_out_path}\")\n",
    "print(f\"  Seed: {args.seed}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Policy Evaluation\n",
    "\n",
    "**Note:** Make sure your model server is running before executing this cell!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Videos will be saved to: data/libero/videos/20251030_162902/libero_spatial\n",
      "INFO:root:Task suite: libero_spatial\n",
      "INFO:root:Waiting for server at ws://0.0.0.0:8001...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Applying task order index 0 (permutation: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) for benchmark 'libero_spatial' (10 tasks).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning]: datasets path /hdd/zijianwang/openpi/third_party/LIBERO-PRO/libero/libero/../datasets does not exist!\n",
      "[Warning]: datasets path /hdd/zijianwang/openpi/third_party/LIBERO-PRO/libero/libero/../datasets does not exist!\n",
      "{'bddl_file_name': PosixPath('/hdd/zijianwang/openpi/third_party/LIBERO-PRO/libero/libero/bddl_files/libero_spatial/pick_up_the_black_bowl_on_the_ramekin_and_place_it_on_the_plate.bddl'), 'camera_heights': 256, 'camera_widths': 256}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting episode 1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear_speed: 0.04449995057193282\n",
      "linear_speed: 0.07264213814136948\n",
      "linear_speed: 0.09830925587567169\n",
      "linear_speed: 0.13172485385010774\n",
      "linear_speed: 0.16437926501377167\n",
      "linear_speed: 0.19019679541492715\n",
      "linear_speed: 0.20694882588643382\n",
      "linear_speed: 0.21605528401734894\n",
      "linear_speed: 0.2229828144728291\n",
      "linear_speed: 0.22785469638847794\n",
      "linear_speed: 0.24025529367097276\n",
      "linear_speed: 0.24882314935189873\n",
      "linear_speed: 0.25431446665935337\n",
      "linear_speed: 0.25799803536876964\n",
      "linear_speed: 0.2577473296914864\n",
      "linear_speed: 0.23907238962141397\n",
      "linear_speed: 0.22788622933931962\n",
      "linear_speed: 0.22265017225745354\n",
      "linear_speed: 0.21361860060103613\n",
      "linear_speed: 0.20436677458727112\n",
      "linear_speed: 0.21173650306783418\n",
      "linear_speed: 0.2156857811201936\n",
      "linear_speed: 0.22502108799748943\n",
      "linear_speed: 0.2325232305882428\n",
      "linear_speed: 0.24142677069592525\n",
      "linear_speed: 0.23323281833934983\n",
      "linear_speed: 0.222234780404894\n",
      "linear_speed: 0.19745954276199115\n",
      "linear_speed: 0.17248769926195215\n",
      "linear_speed: 0.14298089407131265\n",
      "linear_speed: 0.20085687609820133\n",
      "linear_speed: 0.18114895414058357\n",
      "linear_speed: 0.14900658178234952\n",
      "linear_speed: 0.11278554890584912\n",
      "linear_speed: 0.08309863308416139\n",
      "linear_speed: 0.05808714363020668\n",
      "linear_speed: 0.043954921072390594\n",
      "linear_speed: 0.0323030332324815\n",
      "linear_speed: 0.024163878820819086\n",
      "linear_speed: 0.01763258304579173\n",
      "linear_speed: 0.01829227303781263\n",
      "linear_speed: 0.01591643714023649\n",
      "linear_speed: 0.017603017301481134\n",
      "linear_speed: 0.024127591595316265\n",
      "linear_speed: 0.03490908408548445\n",
      "linear_speed: 0.04989294402239682\n",
      "linear_speed: 0.06777600337817359\n",
      "linear_speed: 0.08826049988579288\n",
      "linear_speed: 0.11040176107036227\n",
      "linear_speed: 0.13415595411028908\n",
      "linear_speed: 0.16419676792704013\n",
      "linear_speed: 0.1830095452763909\n",
      "linear_speed: 0.19977894685569786\n",
      "linear_speed: 0.21435448609986202\n",
      "linear_speed: 0.2277041344826358\n",
      "linear_speed: 0.2272205701175527\n",
      "linear_speed: 0.23830500792770132\n",
      "linear_speed: 0.2408017775934132\n",
      "linear_speed: 0.23139417594743078\n",
      "linear_speed: 0.21629900071816122\n",
      "linear_speed: 0.19715084128565832\n",
      "linear_speed: 0.19509400963601406\n",
      "linear_speed: 0.19813344994945767\n",
      "linear_speed: 0.2021903043541314\n",
      "linear_speed: 0.2067191337119259\n",
      "linear_speed: 0.21319099876243638\n",
      "linear_speed: 0.21561124114790078\n",
      "linear_speed: 0.21726183093951004\n",
      "linear_speed: 0.21810973262976358\n",
      "linear_speed: 0.21923133655636476\n",
      "linear_speed: 0.22063935513218183\n",
      "linear_speed: 0.22388149918989042\n",
      "linear_speed: 0.22998930603846807\n",
      "linear_speed: 0.24194687617489438\n",
      "linear_speed: 0.2579822884982871\n",
      "linear_speed: 0.25465063479431715\n",
      "linear_speed: 0.26646962554715586\n",
      "linear_speed: 0.27727858731615085\n",
      "linear_speed: 0.2751385533381684\n",
      "linear_speed: 0.2659485255325401\n",
      "linear_speed: 0.24205332088668505\n",
      "linear_speed: 0.2206335796521009\n",
      "linear_speed: 0.20373287770700949\n",
      "linear_speed: 0.18158741384919028\n",
      "linear_speed: 0.16422859321082411\n",
      "linear_speed: 0.15401689258267842\n",
      "linear_speed: 0.14494924910839818\n",
      "linear_speed: 0.14517674758704224\n",
      "linear_speed: 0.16555540940220706\n",
      "linear_speed: 0.18938305277422407\n",
      "linear_speed: 0.2136571883282892\n",
      "linear_speed: 0.23792179812564543\n",
      "linear_speed: 0.2568492980212928\n",
      "linear_speed: 0.27256600701469713\n",
      "linear_speed: 0.27703340394413517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Video saved to: data/libero/videos/20251030_162902/libero_spatial/task05_ep000_pick_up_the_black_bowl_on_the_ramekin_and_place_it_on_the_plate_success.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear_speed: 0.2643686212530977\n",
      "linear_speed: 0.23821784189193584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Velocity plot saved to: data/libero/videos/20251030_162902/libero_spatial/task05_ep000_pick_up_the_black_bowl_on_the_ramekin_and_place_it_on_the_plate_success_velocity.png\n",
      "INFO:root:Velocity plot saved to: data/libero/videos/20251030_162902/libero_spatial/task05_ep000_pick_up_the_black_bowl_on_the_ramekin_and_place_it_on_the_plate_success_gripper_state.png\n",
      "INFO:root:Success: True\n",
      "INFO:root:# episodes completed so far: 1\n",
      "INFO:root:# successes: 1 (100.0%)\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.37s/it]\n",
      "INFO:root:Current task success rate: 1.0\n",
      "INFO:root:Current total success rate: 1.0\n",
      "100%|██████████| 10/10 [00:07<00:00,  1.41it/s]\n",
      "INFO:root:Total success rate: 1.0\n",
      "INFO:root:Total episodes: 1\n",
      "INFO:root:All videos saved to: data/libero/videos/20251030_162902/libero_spatial\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "# Get current timestamp for this run\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Create timestamped video output directory\n",
    "video_out_dir = pathlib.Path(args.video_out_path) / timestamp / args.task_suite_name\n",
    "video_out_dir.mkdir(parents=True, exist_ok=True)\n",
    "logging.info(f\"Videos will be saved to: {video_out_dir}\")\n",
    "\n",
    "# Initialize LIBERO task suite\n",
    "benchmark_dict = benchmark.get_benchmark_dict()\n",
    "task_suite = benchmark_dict[args.task_suite_name]()\n",
    "num_tasks_in_suite = task_suite.n_tasks\n",
    "logging.info(f\"Task suite: {args.task_suite_name}\")\n",
    "\n",
    "if \"libero_spatial\" in args.task_suite_name:\n",
    "    max_steps = 220  # longest training demo has 193 steps\n",
    "elif \"libero_object\" in args.task_suite_name:\n",
    "    max_steps = 280  # longest training demo has 254 steps\n",
    "elif \"libero_goal\" in args.task_suite_name:\n",
    "    max_steps = 300  # longest training demo has 270 steps\n",
    "elif \"libero_10\" in args.task_suite_name:\n",
    "    max_steps = 520  # longest training demo has 505 steps\n",
    "elif \"libero_90\" in args.task_suite_name:\n",
    "    max_steps = 400  # longest training demo has 373 steps\n",
    "else:\n",
    "    raise ValueError(f\"Unknown task suite: {args.task_suite_name}\")\n",
    "\n",
    "client = _websocket_client_policy.WebsocketClientPolicy(args.host, args.port)\n",
    "\n",
    "# Start evaluation\n",
    "total_episodes, total_successes = 0, 0\n",
    "for task_id in tqdm.tqdm(range(num_tasks_in_suite)):\n",
    "    if task_id != 5:\n",
    "        continue\n",
    "    # Get task\n",
    "    task = task_suite.get_task(task_id)\n",
    "\n",
    "    # Get default LIBERO initial states\n",
    "    initial_states = task_suite.get_task_init_states(task_id)\n",
    "\n",
    "    # Initialize LIBERO environment and task description\n",
    "    env, task_description = _get_libero_env(task, LIBERO_ENV_RESOLUTION, args.seed)\n",
    "\n",
    "    # Start episodes\n",
    "    task_episodes, task_successes = 0, 0\n",
    "    for episode_idx in tqdm.tqdm(range(args.num_trials_per_task)):\n",
    "        # if episode_idx != 0:\n",
    "        #     sys.exit()\n",
    "\n",
    "        # Reset environment\n",
    "        env.reset()\n",
    "        action_plan = collections.deque()\n",
    "\n",
    "        # Set initial states\n",
    "        obs = env.set_init_state(initial_states[episode_idx])\n",
    "        robot_instance = env.robots[0]\n",
    "        # Setup\n",
    "        t = 0\n",
    "        replay_images = []\n",
    "        velocity_trajectory = []  # Store velocity data for visualization\n",
    "        linear_speed_trajectory = []\n",
    "        gripper_state_trajectory = []\n",
    "\n",
    "        logging.info(f\"Starting episode {task_episodes+1}...\")\n",
    "        while t < max_steps + args.num_steps_wait:\n",
    "            try:\n",
    "                # IMPORTANT: Do nothing for the first few timesteps because the simulator drops objects\n",
    "                # and we need to wait for them to fall\n",
    "                if t < args.num_steps_wait:\n",
    "                    obs, reward, done, info = env.step(LIBERO_DUMMY_ACTION)\n",
    "                    velocity_trajectory.append(np.zeros(7))\n",
    "                    linear_speed_trajectory.append(0)\n",
    "                    t += 1\n",
    "                    continue\n",
    "\n",
    "                # Get preprocessed image\n",
    "                # IMPORTANT: rotate 180 degrees to match train preprocessing\n",
    "                img = np.ascontiguousarray(obs[\"agentview_image\"][::-1, ::-1])\n",
    "                wrist_img = np.ascontiguousarray(obs[\"robot0_eye_in_hand_image\"][::-1, ::-1])\n",
    "                img = image_tools.convert_to_uint8(\n",
    "                    image_tools.resize_with_pad(img, args.resize_size, args.resize_size)\n",
    "                )\n",
    "                wrist_img = image_tools.convert_to_uint8(\n",
    "                    image_tools.resize_with_pad(wrist_img, args.resize_size, args.resize_size)\n",
    "                )\n",
    "\n",
    "                # Save preprocessed image for replay video\n",
    "                tempimg = add_text_to_image(img, t)\n",
    "                replay_images.append(tempimg)\n",
    "                if not action_plan:\n",
    "                    # Finished executing previous action chunk -- compute new chunk\n",
    "                    # Prepare observations dict\n",
    "                    element = {\n",
    "                        \"observation/image\": img,\n",
    "                        \"observation/wrist_image\": wrist_img,\n",
    "                        \"observation/state\": np.concatenate(\n",
    "                            (\n",
    "                                obs[\"robot0_eef_pos\"],\n",
    "                                _quat2axisangle(obs[\"robot0_eef_quat\"]),\n",
    "                                obs[\"robot0_gripper_qpos\"],\n",
    "                            )\n",
    "                        ),\n",
    "                        \"prompt\": str(task_description),\n",
    "                    }\n",
    "\n",
    "                    # Query model to get action\n",
    "                    action_chunk = client.infer(element)[\"actions\"]\n",
    "                    assert action_chunk.shape[-2] >= args.replan_steps, (\n",
    "                        f\"We want to replan every {args.replan_steps} steps, but policy only predicts {action_chunk.shape[-2]} steps.\"\n",
    "                    )\n",
    "                    action_chunk = action_chunk[0]\n",
    "                    action_plan.extend(action_chunk[: args.replan_steps])\n",
    "\n",
    "\n",
    "                action = action_plan.popleft()\n",
    "                # print(f\"action: {action}\")\n",
    "\n",
    "                # Execute action in environment\n",
    "                obs, reward, done, info = env.step(action.tolist())\n",
    "                gripper_is_closed_result = is_gripper_closed(obs)\n",
    "                eef_total_velocity = robot_instance._hand_total_velocity  # vx, vy, vz, rx, ry, rz 3个线速度, 3个角速度\n",
    "\n",
    "                # 提取前3个分量作为线速度向量\n",
    "                linear_velocity = eef_total_velocity[:3]\n",
    "\n",
    "                # 计算线速度的幅值\n",
    "                linear_speed = np.linalg.norm(linear_velocity)\n",
    "                # print(f\"linear_speed: {linear_speed}\")\n",
    "                linear_speed_trajectory.append(linear_speed)\n",
    "                gripper_state_trajectory.append(gripper_is_closed_result)\n",
    "                \n",
    "                # Collect velocity data\n",
    "                # velocity = obs[\"robot0_joint_vel\"]\n",
    "                # velocity_trajectory.append(velocity)\n",
    "                # print(velocity)\n",
    "                action_length = len(action.tolist())\n",
    "                if done:\n",
    "                    task_successes += 1\n",
    "                    total_successes += 1\n",
    "                    break\n",
    "                t += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Caught exception: {e}\")\n",
    "                break\n",
    "\n",
    "        task_episodes += 1\n",
    "        total_episodes += 1\n",
    "\n",
    "        # Save a replay video of the episode with unique filename\n",
    "        # Include task_id, episode_idx, and success/failure status\n",
    "        suffix = \"success\" if done else \"failure\"\n",
    "        task_segment = task_description.replace(\" \", \"_\")\n",
    "        video_filename = f\"task{task_id:02d}_ep{episode_idx:03d}_{task_segment}_{suffix}.mp4\"\n",
    "        video_path = video_out_dir / video_filename\n",
    "        \n",
    "        imageio.mimwrite(\n",
    "            video_path,\n",
    "            [np.asarray(x) for x in replay_images],\n",
    "            fps=24,\n",
    "        )\n",
    "        logging.info(f\"Video saved to: {video_path}\")\n",
    "        \n",
    "        # Save velocity trajectory plot\n",
    "        velocity_plot_filename = f\"task{task_id:02d}_ep{episode_idx:03d}_{task_segment}_{suffix}_velocity.png\"\n",
    "        velocity_plot_path = video_out_dir / velocity_plot_filename\n",
    "        _plot_velocity_trajectory(linear_speed_trajectory, str(velocity_plot_path))\n",
    "\n",
    "        # Save gripper state trajectory plot\n",
    "        gripper_state_plot_filename = f\"task{task_id:02d}_ep{episode_idx:03d}_{task_segment}_{suffix}_gripper_state.png\"\n",
    "        gripper_state_plot_path = video_out_dir / gripper_state_plot_filename\n",
    "        _plot_velocity_trajectory(gripper_state_trajectory, str(gripper_state_plot_path))\n",
    "\n",
    "        # Log current results\n",
    "        logging.info(f\"Success: {done}\")\n",
    "        logging.info(f\"# episodes completed so far: {total_episodes}\")\n",
    "        logging.info(f\"# successes: {total_successes} ({total_successes / total_episodes * 100:.1f}%)\")\n",
    "\n",
    "    # Log final results\n",
    "    logging.info(f\"Current task success rate: {float(task_successes) / float(task_episodes)}\")\n",
    "    logging.info(f\"Current total success rate: {float(total_successes) / float(total_episodes)}\")\n",
    "\n",
    "logging.info(f\"Total success rate: {float(total_successes) / float(total_episodes)}\")\n",
    "logging.info(f\"Total episodes: {total_episodes}\")\n",
    "logging.info(f\"All videos saved to: {video_out_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
